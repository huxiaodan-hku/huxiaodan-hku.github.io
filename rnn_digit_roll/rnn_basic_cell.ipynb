{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5   #全部数据一共反复训练次数\n",
    "total_series_length = 50000   \n",
    "truncated_backprop_length = 10     #输入X1,x2,...Xn 的长度\n",
    "state_size = 4     #隐藏层大小\n",
    "num_classes = 2     #输出的class ， 本程序只有0,1两种输出\n",
    "echo_step = 3      #输出偏移位数\n",
    "batch_size = 5     #batch_sizs\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length    #batch 的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据\n",
    "  \n",
    "```\n",
    " inputs_value:          targets_value:\n",
    "[[1 0 0 ..., 1 0 0]   [[0 0 0 ..., 1 1 0]\n",
    " [0 1 1 ..., 0 0 1]    [0 0 0 ..., 1 1 1]\n",
    " [0 1 0 ..., 1 1 1]    [0 0 0 ..., 0 0 0]\n",
    " [1 1 0 ..., 0 0 1]    [0 0 0 ..., 0 0 1]\n",
    " [0 1 1 ..., 1 0 0]]   [0 0 0 ..., 0 0 0]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_value = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "targets_value = np.roll(inputs_value, echo_step)\n",
    "for i in range(num_batches * batch_size):\n",
    "    targets_value[i * truncated_backprop_length : (i * truncated_backprop_length + echo_step)] = 0\n",
    "\n",
    "inputs_value = inputs_value.reshape((batch_size, -1))  \n",
    "targets_value = targets_value.reshape((batch_size, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型\n",
    "```\n",
    "rnn_outputs:\n",
    ">>>Tensor(\"rnn/transpose:0\", shape=(5, 10, 4), dtype=float32)\n",
    "tf.reshape(rnn_outputs, [-1, state_size]):\n",
    ">>>Tensor(\"Reshape:0\", shape=(50, 4), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "one_hot_batchX_placeholder = tf.one_hot(batchX_placeholder , num_classes)\n",
    "\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, one_hot_batchX_placeholder, initial_state=init_state)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W2) + b2,\n",
    "            [batch_size, truncated_backprop_length, num_classes])\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=batchY_placeholder, logits=logits)\n",
    "\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.70098\n",
      "Step 100 Batch loss 0.42059\n",
      "Step 200 Batch loss 0.010894\n",
      "Step 300 Batch loss 0.00570092\n",
      "Step 400 Batch loss 0.00321913\n",
      "Step 500 Batch loss 0.00323861\n",
      "Step 600 Batch loss 0.00242459\n",
      "Step 700 Batch loss 0.00200511\n",
      "Step 800 Batch loss 0.00172231\n",
      "Step 900 Batch loss 0.00124845\n",
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.00105245\n",
      "Step 100 Batch loss 0.00121114\n",
      "Step 200 Batch loss 0.000874155\n",
      "Step 300 Batch loss 0.000854327\n",
      "Step 400 Batch loss 0.000702099\n",
      "Step 500 Batch loss 0.000879682\n",
      "Step 600 Batch loss 0.000777922\n",
      "Step 700 Batch loss 0.000725159\n",
      "Step 800 Batch loss 0.000692487\n",
      "Step 900 Batch loss 0.000545684\n",
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.000490697\n",
      "Step 100 Batch loss 0.000592507\n",
      "Step 200 Batch loss 0.00044976\n",
      "Step 300 Batch loss 0.000456264\n",
      "Step 400 Batch loss 0.000391093\n",
      "Step 500 Batch loss 0.000504155\n",
      "Step 600 Batch loss 0.000460278\n",
      "Step 700 Batch loss 0.00043969\n",
      "Step 800 Batch loss 0.000430921\n",
      "Step 900 Batch loss 0.000348337\n",
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.000319283\n",
      "Step 100 Batch loss 0.000390936\n",
      "Step 200 Batch loss 0.000301999\n",
      "Step 300 Batch loss 0.000310358\n",
      "Step 400 Batch loss 0.00027047\n",
      "Step 500 Batch loss 0.000352204\n",
      "Step 600 Batch loss 0.000326097\n",
      "Step 700 Batch loss 0.000314724\n",
      "Step 800 Batch loss 0.000312079\n",
      "Step 900 Batch loss 0.000255602\n",
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.000236439\n",
      "Step 100 Batch loss 0.000291273\n",
      "Step 200 Batch loss 0.000227083\n",
      "Step 300 Batch loss 0.000234835\n",
      "Step 400 Batch loss 0.000206511\n",
      "Step 500 Batch loss 0.0002702\n",
      "Step 600 Batch loss 0.000252213\n",
      "Step 700 Batch loss 0.00024475\n",
      "Step 800 Batch loss 0.000244336\n",
      "Step 900 Batch loss 0.000201769\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        _current_cell_state = np.zeros((batch_size, state_size))\n",
    "        _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = inputs_value[:,start_idx:end_idx]\n",
    "            batchY = targets_value[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step = sess.run(\n",
    "                [total_loss, train_step],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
